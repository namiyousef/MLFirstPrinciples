{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutout\n",
    "\n",
    "An exploratory analysis into how different types of [Cutout](https://github.com/uoguelph-mlrg/Cutout) affect model performance on the CIFAR10 dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "class CutoutDispersed:\n",
    "    \"\"\"Randomly mask out pixels from an image\n",
    "    Args:\n",
    "        n_pixels (int): Number of pixels to mask\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_pixels):\n",
    "        self.n_pixels = n_pixels\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "        c = img.size(0)\n",
    "        h = img.size(1) # double check if width / height correct!\n",
    "        w = img.size(2)\n",
    "        \n",
    "        N = h*w        \n",
    "        mask = torch.cat(\n",
    "            (torch.randint(0, w, size=(self.n_pixels, 1)),\n",
    "            torch.randint(0, h, size=(self.n_pixels, 1))),\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        mask = torch.randperm(N)[:self.n_pixels]\n",
    "        for i in range(c):\n",
    "            img[i].flatten()[mask] = 0\n",
    "            \n",
    "        return img\n",
    "\n",
    "class CutoutOfficial:\n",
    "    \"\"\"Randomly mask out one or more patches from an image.\n",
    "    Args:\n",
    "        n_holes (int): Number of patches to cut out of each image.\n",
    "        length (int): The length (in pixels) of each square patch.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_holes, length):\n",
    "        self.n_holes = n_holes\n",
    "        self.length = length\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "\n",
    "        mask = np.ones((h, w), np.float32)\n",
    "\n",
    "        for n in range(self.n_holes):\n",
    "            y = np.random.randint(h)\n",
    "            x = np.random.randint(w)\n",
    "\n",
    "            y1 = np.clip(y - self.length // 2, 0, h)\n",
    "            y2 = np.clip(y + self.length // 2, 0, h)\n",
    "            x1 = np.clip(x - self.length // 2, 0, w)\n",
    "            x2 = np.clip(x + self.length // 2, 0, w)\n",
    "\n",
    "            mask[y1: y2, x1: x2] = 0.\n",
    "\n",
    "        mask = torch.from_numpy(mask)\n",
    "        mask = mask.expand_as(img)\n",
    "        img = img * mask\n",
    "\n",
    "        return img\n",
    "    \n",
    "class CutoutVariable:\n",
    "    \"\"\"Randomly mask out one or more patches (or random size) from an image.\n",
    "    Args:\n",
    "        max_size (int): The maximum size of the square patch\n",
    "        n_masks (int): Number of patches to cut out of each image.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, max_size, n_masks=1):\n",
    "        self.max_size = max_size\n",
    "        self.n_masks = n_masks\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (Tensor): Tensor image of size (C, H, W).\n",
    "        Returns:\n",
    "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
    "        \"\"\"\n",
    "        h = img.size(1)\n",
    "        w = img.size(2)\n",
    "        \n",
    "        if isinstance(self.max_size, int):\n",
    "            size_h = size_w = int(torch.randint(0, high=self.max_size+1, size=(1,)))\n",
    "        else:\n",
    "            \n",
    "            size_h = int(torch.randint(0, high=self.max_size[0]+1, size=(1,)))\n",
    "            size_w = int(torch.randint(0, high=self.max_size[1]+1, size=(1,)))\n",
    "        \n",
    "        i = int(torch.randint(0, high=h - size_h, size=(1,)))\n",
    "        j = int(torch.randint(0, high=w - size_w, size=(1,)))\n",
    "        img[..., i:i+size_h, j:j+size_w] = 0\n",
    "        # TODO not sure if logic correct\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Cutout(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), Cutout(1, 4)])\n",
    "\n",
    "batch_size = 16  # sets batch_size to 16 for training and saving data!\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)  # TODO set shuffle back to True\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:206] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:206] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n"
     ]
    }
   ],
   "source": [
    "for i, (inputs, outputs) in enumerate(trainloader):\n",
    "    im = Image.fromarray(\n",
    "                        (torch.cat(\n",
    "                            inputs.to('cpu').split(1, 0), 3\n",
    "                        ).squeeze() / 2 * 255 + .5 * 255).permute(1, 2, 0).numpy().astype('uint8')\n",
    "                    )\n",
    "    im.save(\"cutout.png\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [0., 0., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones((3,5,5))\n",
    "m = CutoutVariable(5)\n",
    "m(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.ones((3,5,5))\n",
    "A[:, 0].flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.randperm(5)[:2]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 1, 3, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp0090",
   "language": "python",
   "name": "comp0090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
